{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab52f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for uploading! We're confident that the audio file is indeed made by Lil Uzi Vert. However, please note that it is a fake, generated file created by artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import openai\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle \n",
    "import json\n",
    "from Shazam import ShazamSong\n",
    "\n",
    "\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = '/users/seanmullins333/desktop/Tour.wav'\n",
    "\n",
    "final_json = {\n",
    "            'MFCCs': [],\n",
    "            'Spec_Con': [] }\n",
    "\n",
    "n_mfcc = 40\n",
    "\n",
    "try:\n",
    "    y, sr = librosa.load(file_path, sr=None, duration=100, offset=30)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    sc = librosa.feature.spectral_contrast(y=y, sr=sr)  \n",
    "\n",
    "    final_json['MFCCs'].append(mfccs)\n",
    "    final_json['Spec_Con'].append(sc)\n",
    "\n",
    "except:\n",
    "    print('Error with {}'.format(file_path))\n",
    "\n",
    "\n",
    "mfcc_df_mean = pd.DataFrame(np.mean(final_json['MFCCs'][0], axis=1)).transpose()\n",
    "mfcc_df_var = pd.DataFrame(np.var(final_json['MFCCs'][0], axis=1)).transpose()\n",
    "\n",
    "sc_df = pd.DataFrame([np.mean(inner_array, axis=1) for inner_array in final_json['Spec_Con']])\n",
    "\n",
    "mfcc_df = mfcc_df_mean.merge(mfcc_df_var, how='left', left_index=True, right_index=True)\n",
    "\n",
    "mfcc_df = mfcc_df.merge(sc_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "new_column_names = ['Column' + str(i+1) for i in range(len(mfcc_df.columns))]\n",
    "\n",
    "mfcc_df.columns = new_column_names\n",
    "\n",
    "\n",
    "with open('SVM-model', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open('SVM-scaler', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "mfcc_df_scaled = scaler.transform(mfcc_df)\n",
    "\n",
    "y_pred = model.predict(mfcc_df_scaled)\n",
    "y_proba = model.predict_proba(mfcc_df_scaled)\n",
    "\n",
    "max_proba = round(y_proba.max() * 100, 2)\n",
    "\n",
    "with open('SVM-key', 'r') as file:\n",
    "    SVM_key = json.load(file)\n",
    "\n",
    "keys = [key for key, value in SVM_key.items() if value == y_pred[0]]\n",
    "\n",
    "#Now the shazam block\n",
    "\n",
    "Shazam_Artist = ShazamSong(file_path)\n",
    "\n",
    "# if Shazam_Artist is None:\n",
    "\n",
    "if max_proba >= 50 and (Shazam_Artist == keys[0]):\n",
    "    response = openai.Completion.create(\n",
    "    engine='text-davinci-003',  # Use the ADA model\n",
    "    prompt='A user just uploaded an audio file to my web app. The song is by {}. Casually tell the user that we are confident it is by {} and that it is not fake and not artificially generated.'.format(Shazam_Artist, Shazam_Artist),  # Specify your prompt or instructions\n",
    "\n",
    "    max_tokens=50  # Set the desired length of the generated paragraph\n",
    ")\n",
    "    paragraph = response.choices[0].text.strip()  # Get the generated paragraph\n",
    "    print (paragraph)\n",
    "\n",
    "if max_proba >= 50 and (Shazam_Artist != keys[0] or Shazam_Artist is None):\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',  # Use the ADA model\n",
    "        prompt='A user just uploaded an audio file to my web app. The song is by {}. Casually tell the user that we are confident it is by {} and that it is fake, and artificially generated.'.format(keys[0], keys[0]),  # Specify your prompt or instructions\n",
    "        max_tokens=50  # Set the desired length of the generated paragraph\n",
    "    )\n",
    "    paragraph = response.choices[0].text.strip()  # Get the generated paragraph\n",
    "    print( paragraph)\n",
    "\n",
    "else:\n",
    "    print( \"Hmm... I'm not sure we can identify that song. It is possible it has a featured artist in it...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae18535",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shazam_Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba064907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='Hey.wav'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ShazamAPI import Shazam\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# def ShazamSong(file_path):\n",
    "    \n",
    "audio_file_path = '/users/seanmullins333/desktop/Tour.wav'\n",
    "\n",
    "audio = AudioSegment.from_file(audio_file_path)\n",
    "\n",
    "\n",
    "start_time = 30000  # 30 seconds\n",
    "end_time = len(audio)  # End of the audio (full length)\n",
    "\n",
    "# Trim the audio to the specified time range\n",
    "trimmed_audio = audio[start_time:end_time]\n",
    "\n",
    "\n",
    "trimmed_audio.export('Hey.wav')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41201dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lil Uzi Vert\n"
     ]
    }
   ],
   "source": [
    "mp3_file_content_to_recognize = open('Hey.wav', 'rb').read()\n",
    "\n",
    "\n",
    "shazam = Shazam(mp3_file_content_to_recognize)\n",
    "\n",
    "recognize_generator = shazam.recognizeSong()\n",
    "\n",
    "try:\n",
    "    result = next(recognize_generator)\n",
    "    artist = result[1]['track']['subtitle']\n",
    "    print(artist)\n",
    "except (StopIteration, KeyError):\n",
    "    print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
